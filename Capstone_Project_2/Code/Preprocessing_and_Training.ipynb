{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ddc5b0",
   "metadata": {},
   "source": [
    "# Preprocessing and Training\n",
    "In this part of Capstone Project 2, the data will be preprocessed to make it ready for use in machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e8ed66",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [1 Import Packages and Load Data](#1-Import-Packages-and-Load-Data)\n",
    "* [2 Initial Preprocessing](#2-Initial-Preprocessing)\n",
    "    * [2.1 Imputing Missing Values](#2.1-Imputing-Missing-Values)\n",
    "    * [2.2 Removing Rows Without Target Labels](#2.2-Removing-Rows-Without-Target-Labels)\n",
    "    * [2.3 Splitting Dataframe into Feature Matrix and Target Vector](#2.3-Splitting-Dataframe-into-Feature-Matrix-and-Target-Vector)\n",
    "* [3 One Hot Encoding of Categorical Features](#3-One-Hot-Encoding-of-Categorical-Features)\n",
    "* [4 Train-Test Split](#4-Train-Test-Split)\n",
    "* [5 Scaling Numeric Features](#5-Scaling-Numeric-Features)\n",
    "* [6 Export Results](#6-Export-Results)\n",
    "* [7 Final Remarks](#7-Final-Remarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d241035c",
   "metadata": {},
   "source": [
    "# 1 Import Packages and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "369df16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d018bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/df_clean_null.pkl'\n",
    "df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cb4f73",
   "metadata": {},
   "source": [
    "# 2 Initial Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6866c1",
   "metadata": {},
   "source": [
    "## 2.1 Imputing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdb4fe9",
   "metadata": {},
   "source": [
    "**Defining Imputer Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fcf7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer(dataframe, category_value_tofill, columns_drop, columns_mode, columns_median):\n",
    "    '''Imputes missing values to the input dataframe.\n",
    "    \n",
    "       Parameters\n",
    "       ----------\n",
    "       dataframe: Pandas dataframe\n",
    "           dataframe with which to impute missing values.\n",
    "       \n",
    "       category_value_tofill: int, float, or string\n",
    "           Value to used to fill missing values in categorical features.\n",
    "       \n",
    "       columns_drop: list-like\n",
    "           List of columns to drop.\n",
    "       \n",
    "       columns_mode: list-like\n",
    "           List of numeric columns to impute with the mode.\n",
    "           \n",
    "       columns_median: list-like\n",
    "           List of numeric columns to impute with the mean.\n",
    "    '''\n",
    "    \n",
    "    #Fill null values in categorical features with value_null\n",
    "    for column in dataframe.select_dtypes(include='category'):\n",
    "        if any(dataframe[column].isnull()):\n",
    "            dataframe[column] = dataframe[column].cat.add_categories([category_value_tofill])\n",
    "            dataframe[column] = dataframe[column].fillna(value=category_value_tofill)\n",
    "            \n",
    "    #Droping columns, imputing with mode, and imputing with median.\n",
    "    dataframe = dataframe.drop(columns=columns_drop)\n",
    "    dataframe = dataframe.fillna(dataframe[columns_mode].mode().iloc[0, :])\n",
    "    dataframe = dataframe.fillna(dataframe[columns_median].median())\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e7982d",
   "metadata": {},
   "source": [
    "**Defining Parameters for the Imputing Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fecabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill null values in categorical features with this one\n",
    "val_null = 999.0\n",
    "\n",
    "#Columns to drop\n",
    "cols_to_drop = ['POORHLTH_ALT', 'DIABAGE2_ALT', 'AVEDRNK2_ALT', 'DRNK3GE5_ALT', 'MAXDRNKS_ALT', \\\n",
    "                'BLDSUGAR_ALT', 'FEETCHK2_ALT', 'DOCTDIAB_ALT', 'CHKHEMO3_ALT', 'FEETCHK_ALT', \\\n",
    "                'LONGWTCH_ALT', 'ASTHMAGE_ALT', 'ASERVIST_ALT', 'ASDRVIST_ALT', 'ASRCHKUP_ALT', \\\n",
    "                'ASACTLIM_ALT', 'SCNTWRK1_ALT', 'SCNTLWK1_ALT', '_STRWT', '_CLLCPWT', '_DUALCOR', \\\n",
    "                'EXACTOT1', 'EXACTOT2', 'IDATE', 'SEQNO', '_PSU', 'HIVTSTD3', 'CVDINFR4', \\\n",
    "                'CVDCRHD4', 'HAREHAB1', 'STREHAB1']\n",
    "\n",
    "#Columns to impute with mode\n",
    "cols_imp_mode = ['NUMADULT', 'NUMMEN', 'NUMWOMEN', 'HHADULT_ALT', 'PHYSHLTH_ALT', 'MENTHLTH_ALT', \\\n",
    "                 'CHILDREN_ALT', 'ALCDAY5_ALT', 'ADPLEASR_ALT', 'ADDOWN_ALT', 'ADSLEEP_ALT', 'ADENERGY_ALT', \\\n",
    "                 'ADEAT1_ALT', 'ADFAIL_ALT', 'ADTHINK_ALT', 'ADMOVE_ALT', 'FTJUDA1_', 'FRUTDA1_', 'BEANDAY_', \\\n",
    "                 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_FRUTSUM', '_VEGESUM']\n",
    "\n",
    "#Columns to impute with median\n",
    "cols_imp_median = ['HTIN4', 'HTM4', 'WTKG3_ALT', '_BMI5', 'METVL11_', 'METVL21_', 'MAXVO2__ALT', 'FC60__ALT', \\\n",
    "                   'PADUR1_', 'PADUR2_', 'PAFREQ1__ALT', 'PAFREQ2__ALT', '_MINAC11', '_MINAC21', \\\n",
    "                   'STRFREQ__ALT', 'PAMIN11_', 'PAMIN21_', 'PA1MIN_', 'PAVIG11_', 'PAVIG21_', 'PA1VIGM_',\\\n",
    "                  'DROCDY3__ALT', '_DRNKWEK_ALT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a6bce8",
   "metadata": {},
   "source": [
    "**Applying Imputing Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7af3d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = imputer(df, val_null, cols_to_drop, cols_imp_mode, cols_imp_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f70719",
   "metadata": {},
   "source": [
    "## 2.2 Removing Rows Without Target Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935b87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_drop = df[df['_MICHD'] == val_null].index\n",
    "df = df.drop(labels = index_to_drop)\n",
    "df['_MICHD'] = df['_MICHD'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3076bf",
   "metadata": {},
   "source": [
    "## 2.3 Splitting Dataframe into Feature Matrix and Target Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d5e529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['_MICHD'].map({1.0:1.0, 2.0:0.0}) #Remapping of labels: 0.0 means \"No\", 1.0 means \"Yes\"\n",
    "X = df.drop(columns=['_MICHD'])\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38293dda",
   "metadata": {},
   "source": [
    "# 3 One Hot Encoding of Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c108c",
   "metadata": {},
   "source": [
    "**Splitting the Features**  \n",
    "There are three different types of transformations that will be applied to different types of features: categorical, skewed numeric, and non-skewed numeric. Different transformations will be applied to these subsets. One hot encoding will be applied to categorical features, quantile transformation will be applied to numeric features that have right-skewed distributions, and standard scaling will be applied to numeric features that approximate gaussian distributions.\n",
    "\n",
    "One thing to keep in mind is that the one hot encoding will happen before the train-test split, but the quantile transformation and the standard scaling will happen after it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f14f50ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X.select_dtypes(include='category').columns\n",
    "\n",
    "skewed_num_cols = ['NUMADULT', 'NUMMEN', 'NUMWOMEN', 'HHADULT_ALT', 'PHYSHLTH_ALT', 'MENTHLTH_ALT', \\\n",
    "                   'CHILDREN_ALT', 'ALCDAY5_ALT', 'ADPLEASR_ALT', 'ADDOWN_ALT', 'ADSLEEP_ALT', \\\n",
    "                   'ADENERGY_ALT', 'ADEAT1_ALT', 'ADFAIL_ALT', 'ADTHINK_ALT', 'ADMOVE_ALT', '_RAWRAKE', \\\n",
    "                   '_WT2RAKE', '_LLCPWT', 'WTKG3_ALT', '_BMI5', 'DROCDY3__ALT', '_DRNKWEK_ALT', \\\n",
    "                   'FTJUDA1_', 'FRUTDA1_', 'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_MISFRTN', \\\n",
    "                   '_MISVEGN', '_FRUTSUM', '_VEGESUM', 'METVL11_', 'METVL21_', 'PADUR1_', \\\n",
    "                   'PADUR2_', 'PAFREQ1__ALT', 'PAFREQ2__ALT', '_MINAC11', '_MINAC21', 'STRFREQ__ALT', \\\n",
    "                   'PAMIN11_', 'PAMIN21_', 'PA1MIN_', 'PAVIG11_', 'PAVIG21_', 'PA1VIGM_']\n",
    "\n",
    "non_skewed_num_cols = [column for column in X.select_dtypes(include='float').columns \\\n",
    "                       if column not in skewed_num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dc60d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = X[cat_cols]\n",
    "X_skewed = X[skewed_num_cols]\n",
    "X_non_skewed = X[non_skewed_num_cols]\n",
    "\n",
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb647b",
   "metadata": {},
   "source": [
    "**Saving Column Names of Numeric Features**  \n",
    "Eventually, the feature matrix will become a sparse matrix and its column labels will be lost. I will therefore save them now so I can later search the columns of the sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9de05c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_col_names = X_skewed.columns\n",
    "non_skewed_col_names = X_non_skewed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c420de",
   "metadata": {},
   "source": [
    "**One Hot Encoding and Making Matrices of Numeric Features Sparse**  \n",
    "The output of the one hot encoder is a sparse matrix. To be able to concatenate the three matrices, the other two need to also be made into sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2fc891",
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_encoder = OneHotEncoder()\n",
    "X_cat = oh_encoder.fit_transform(X_cat)\n",
    "\n",
    "X_skewed = sparse.csr_matrix(X_skewed)\n",
    "\n",
    "X_non_skewed = sparse.csr_matrix(X_non_skewed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2085e60d",
   "metadata": {},
   "source": [
    "**Saving Column Names of One Hot Encoded Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b6e8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_names = oh_encoder.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e21b72",
   "metadata": {},
   "source": [
    "**List of all Column Names after One-Hot Endocing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff034fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = np.concatenate((cat_col_names, np.array(skewed_col_names), np.array(non_skewed_col_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79caf980",
   "metadata": {},
   "source": [
    "**Getting Slices for each of the Three Subsets**  \n",
    "Once the three subsets get transformed into sparse matrices, they lose their column labels, so they can't be used for accessing them. In order to access these subsets after they get concatenated, we need to get their slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63523ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_slice = slice(0, X_cat.shape[1])\n",
    "skewed_slice = slice(cat_slice.stop, cat_slice.stop + X_skewed.shape[1])\n",
    "non_skewed_slice = slice(skewed_slice.stop, skewed_slice.stop + X_non_skewed.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34149a0",
   "metadata": {},
   "source": [
    "**Concatenating the Three Subsets after One Hot Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "748acd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sparse.hstack([X_cat, X_skewed, X_non_skewed], format='csr')\n",
    "\n",
    "del X_cat, X_skewed, X_non_skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ca006",
   "metadata": {},
   "source": [
    "# 4 Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ad254",
   "metadata": {},
   "source": [
    "**Checking Proportion of Positive Labels**  \n",
    "This shows that the dataset is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "273d9eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08830117436242041, 0.9116988256375795)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_1 = len(y[y == 1]) / len(y)\n",
    "prop_0 = 1 - prop_1\n",
    "\n",
    "prop_1, prop_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f2667",
   "metadata": {},
   "source": [
    "**Train-Test Split with Stratification**  \n",
    "Since the dataset is imbalance, we want to make sure that in both the training and test set the proportion of positive labels is similar to what it was before the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb360e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)\n",
    "\n",
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593259ed",
   "metadata": {},
   "source": [
    "Checking that the proportion of positive labels is similar after the split as before the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf470267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08830008199742294,\n",
       " 0.9116999180025771,\n",
       " 0.08830554380992651,\n",
       " 0.9116944561900735)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_1_train = len(y_train[y_train==1]) / len(y_train)\n",
    "prop_0_train = 1 - prop_1_train\n",
    "\n",
    "prop_1_test = len(y_test[y_test==1]) / len(y_test)\n",
    "prop_0_test = 1 - prop_1_test\n",
    "\n",
    "prop_1_train, prop_0_train, prop_1_test, prop_0_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32602a",
   "metadata": {},
   "source": [
    "# 5 Scaling Numeric Features\n",
    "For each of the train and test feature matrices, the features will be scaled so that they have similar orders of magnitude. However, two different types of scaling will be applied to the numeric features. Quantile transformation will be applied to numeric features that have right-skewed distributions, while standard scaling will be applied to features that have approximate gaussian distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464cc840",
   "metadata": {},
   "source": [
    "**Splitting into Subsets**  \n",
    "We use the previously defined slices to split the features into the three subsets again: categorical features, skewed features, and non-skewed features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4cbfb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat = X_train[:, cat_slice]\n",
    "X_train_skewed = X_train[:, skewed_slice]\n",
    "X_train_non_skewed = X_train[:, non_skewed_slice]\n",
    "\n",
    "X_test_cat = X_test[:, cat_slice]\n",
    "X_test_skewed = X_test[:, skewed_slice]\n",
    "X_test_non_skewed = X_test[:, non_skewed_slice]\n",
    "\n",
    "del X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fabf8c6",
   "metadata": {},
   "source": [
    "**Applying Quantile Transformation on Right-Skewed Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebd94d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_transformer = QuantileTransformer()\n",
    "q_transformer.fit(X_train_skewed)\n",
    "\n",
    "X_train_skewed = q_transformer.transform(X_train_skewed)\n",
    "X_test_skewed = q_transformer.transform(X_test_skewed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd44161",
   "metadata": {},
   "source": [
    "**Applying Standard Scaling on Gaussian-Distributed Features**  \n",
    "It's important to note that features cannot be centered during standard scaling if the feature matrix is sparse. Therefore, the feature submatrix has to be made dense first, then scaled, then made sparse again, and finally be concatenated with the other two submatrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a33505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the matrices dense\n",
    "X_train_non_skewed_dense = X_train_non_skewed.toarray()\n",
    "X_test_non_skewed_dense = X_test_non_skewed.toarray()\n",
    "\n",
    "#Initializing and fitting the scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_non_skewed_dense)\n",
    "\n",
    "#Applying the scaling to the dense matrices\n",
    "X_train_non_skewed_dense = scaler.transform(X_train_non_skewed_dense)\n",
    "X_test_non_skewed_dense = scaler.transform(X_test_non_skewed_dense)\n",
    "\n",
    "#Making the matrices sparse again\n",
    "X_train_non_skewed = sparse.csr_matrix(X_train_non_skewed_dense)\n",
    "X_test_non_skewed = sparse.csr_matrix(X_test_non_skewed_dense)\n",
    "\n",
    "del X_train_non_skewed_dense, X_test_non_skewed_dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f61ec6",
   "metadata": {},
   "source": [
    "**Concatenating the Submatrices After Applying Transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3268e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sparse.hstack([X_train_cat, X_train_skewed, X_train_non_skewed])\n",
    "X_test = sparse.hstack([X_test_cat, X_test_skewed, X_test_non_skewed])\n",
    "\n",
    "del X_train_cat, X_train_skewed, X_train_non_skewed\n",
    "del X_test_cat, X_test_skewed, X_test_non_skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bbd585",
   "metadata": {},
   "source": [
    "# 6 Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6183413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/preprocessed.pkl.zip', 'wb') as f:\n",
    "    dump_list = [col_names, X_train, X_test, y_train, y_test]\n",
    "    dump_list.insert(0, len(dump_list))\n",
    "    for x in dump_list:\n",
    "        pickle.dump(x, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f8ddc",
   "metadata": {},
   "source": [
    "# 7 Final Remarks\n",
    "The data has now been preprocessed. I have used one hot encoding on categorical features, split the data into a training set and a test set, and applied appropriate scaling to numeric features. The data stored in the variables X_train, X_test, y_train, and y_test are now ready to be used as input for machine learning algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "88290e038b87e2cdb6a37058d27d18dea0a708f5e3ed04873cad7201dff76582"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
